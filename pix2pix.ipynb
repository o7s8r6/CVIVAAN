{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NFhAzQB3aNMa"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/o7s8r6/CVIVAAN/blob/main/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEYvcfHRB8dw"
      },
      "source": [
        "![pyimagesearch_university_logo.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Image Translation with Pix2Pix\n",
        "### by [PyImageSearch.com](http://www.pyimagesearch.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntZ1AkXZIxY"
      },
      "source": [
        "## Welcome to **[PyImageSearch University](https://pyimg.co/university)** Jupyter Notebooks!\n",
        "\n",
        "This notebook is associated with the [Image Translation with Pix2Pix](https://pyimg.co/ma1qi) blog post published on 2022-07-27.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "As a reminder, these PyImageSearch University Jupyter Notebooks are not for sharing; please refer to the **Copyright** directly below and **Code License Agreement** in the last cell of this notebook. \n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "*PyImageSearch Team*\n",
        "\n",
        "<hr>\n",
        "\n",
        "***Copyright:*** *The contents of this Jupyter Notebook, unless otherwise indicated, are Copyright 2022 OptiReto, LLC and PyImageSearch.com. All rights reserved. Content like this is made possible by the time invested by the authors. If you received this Jupyter Notebook and did not purchase it, please consider making future content possible by joining PyImageSearch University at https://pyimg.co/university today.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3.us-west-2.amazonaws.com/pix2pix/pix2pix.zip\n",
        "!unzip -qq pix2pix.zip\n",
        "%cd pix2pix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import tensorflow and fix the random seed for better reproducibility\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from matplotlib.pyplot import subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "class Config(object):\n",
        "\t# name of the dataset we will be using \n",
        "\tDATASET = \"cityscapes\"\n",
        "\n",
        "\t# build the dataset URL\n",
        "\tDATASET_URL  = f\"http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{DATASET}.tar.gz\"\n",
        "\n",
        "\t# define the batch size\n",
        "\tTRAIN_BATCH_SIZE = 32\n",
        "\tINFER_BATCH_SIZE = 8\n",
        "\n",
        "\t# dataset specs\n",
        "\tIMAGE_WIDTH = 256\n",
        "\tIMAGE_HEIGHT = 256\n",
        "\tIMAGE_CHANNELS = 3\n",
        "\n",
        "\t# training specs\n",
        "\tLEARNING_RATE = 2e-4\n",
        "\tEPOCHS = 15\n",
        "\tSTEPS_PER_EPOCH = 2\n",
        "\n",
        "\t# path to the base output directory\n",
        "\tBASE_OUTPUT_PATH = \"outputs\"\n",
        "\tTEMP_BASE_OUTPUT_PATH = \"temp_outputs\"\n",
        "\n",
        "\t# path to the pix2pix generator\n",
        "\tGENERATOR_MODEL = os.path.join(\n",
        "\t\tBASE_OUTPUT_PATH, \"models\", \"generator\"\n",
        "\t)\n",
        "\tTEMP_GENERATOR_MODEL = os.path.join(\n",
        "\t\tTEMP_BASE_OUTPUT_PATH, \"models\", \"generator\"\n",
        "\t)\n",
        "\n",
        "\t# path to the inferred images and to the grid image\n",
        "\tBASE_IMAGES_PATH = os.path.join(BASE_OUTPUT_PATH, \"images\")\n",
        "\tGRID_IMAGE_PATH = os.path.join(BASE_IMAGES_PATH, \"grid.png\")\n",
        "\tTEMP_BASE_IMAGES_PATH = os.path.join(TEMP_BASE_OUTPUT_PATH, \"images\")\n",
        "\tTEMP_GRID_IMAGE_PATH = os.path.join(TEMP_BASE_IMAGES_PATH, \"grid.png\")\n",
        "\n",
        "config = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the `cityscape` dataset"
      ],
      "metadata": {
        "id": "skwlgCqqrj_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the cityscape training dataset \n",
        "print(\"[INFO] downloading the dataset...\")\n",
        "pathToZip = get_file(\n",
        "\tfname=f\"{config.DATASET}.tar.gz\",\n",
        "\torigin=config.DATASET_URL ,\n",
        "\textract=True\n",
        ")\n",
        "pathToZip  = pathlib.Path(pathToZip)\n",
        "path = pathToZip.parent/config.DATASET"
      ],
      "metadata": {
        "id": "A-tVXjC1ogSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Utilities"
      ],
      "metadata": {
        "id": "-ifyi1wFoxkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the module level autotune\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "def load_image(imageFile):\n",
        "\t# read and decode an image file from the path\n",
        "\timage = tf.io.read_file(imageFile)\n",
        "\timage = tf.io.decode_jpeg(image, channels=3)\n",
        "\n",
        "\t# calculate the midpoint of the width and split the\n",
        "\t# combined image into input mask and real image \n",
        "\twidth = tf.shape(image)[1]\n",
        "\tsplitPoint = width // 2\n",
        "\tinputMask = image[:, splitPoint:, :]\n",
        "\trealImage = image[:, :splitPoint, :]\n",
        "\n",
        "\t# convert both images to float32 tensors and\n",
        "\t# convert pixels to the range of -1 and 1\n",
        "\tinputMask = tf.cast(inputMask, tf.float32)/127.5 - 1\n",
        "\trealImage = tf.cast(realImage, tf.float32)/127.5 - 1\n",
        "\n",
        "\t# return the input mask and real label image\n",
        "\treturn (inputMask, realImage)"
      ],
      "metadata": {
        "id": "0FMo83XroxAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_jitter(inputMask, realImage, height, width):\n",
        "\t# upscale the images for cropping purposes\n",
        "\tinputMask = tf.image.resize(inputMask, [height, width],\n",
        "\t\tmethod=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\trealImage = tf.image.resize(realImage, [height, width],\n",
        "\t\tmethod=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "\t# return the input mask and real label image\n",
        "\treturn (inputMask, realImage)"
      ],
      "metadata": {
        "id": "NPpZ8HKgosXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReadTrainExample(object):\n",
        "\tdef __init__(self, imageHeight, imageWidth):\n",
        "\t\tself.imageHeight = imageHeight\n",
        "\t\tself.imageWidth = imageWidth\n",
        "\t\n",
        "\tdef __call__(self, imageFile):\n",
        "\t\t# read the file path and unpack the image pair\n",
        "\t\tinputMask, realImage = load_image(imageFile)\n",
        "\n",
        "\t\t# perform data augmentation\n",
        "\t\t(inputMask, realImage) = random_jitter(inputMask, realImage,\n",
        "\t\t\tself.imageHeight+30, self.imageWidth+30)\n",
        "\n",
        "\t\t# reshape the input mask and real label image\n",
        "\t\tinputMask = tf.image.resize(inputMask,\n",
        "\t\t\t[self.imageHeight, self.imageWidth])\n",
        "\t\trealImage = tf.image.resize(realImage,\n",
        "\t\t\t[self.imageHeight, self.imageWidth])\n",
        "\n",
        "\t\t# return the input mask and real label image\n",
        "\t\treturn (inputMask, realImage)"
      ],
      "metadata": {
        "id": "KQZ6nVaNo2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReadTestExample(object):\n",
        "\tdef __init__(self, imageHeight, imageWidth):\n",
        "\t\tself.imageHeight = imageHeight\n",
        "\t\tself.imageWidth = imageWidth\n",
        "\n",
        "\tdef __call__(self, imageFile):\n",
        "\t\t# read the file path and unpack the image pair\n",
        "\t\t(inputMask, realImage) = load_image(imageFile)\n",
        "\n",
        "\t\t# reshape the input mask and real label image\n",
        "\t\tinputMask = tf.image.resize(inputMask,\n",
        "\t\t\t[self.imageHeight, self.imageWidth])\n",
        "\t\trealImage = tf.image.resize(realImage,\n",
        "\t\t\t[self.imageHeight, self.imageWidth])\n",
        "\n",
        "\t\t# return the input mask and real label image\n",
        "\t\treturn (inputMask, realImage)"
      ],
      "metadata": {
        "id": "AYWjh-8vo5QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path, batchSize, height, width, train=False):\n",
        "\t# check if this is the training dataset\n",
        "\tif train:\n",
        "\t\t# read the training examples\n",
        "\t\tdataset = tf.data.Dataset.list_files(str(path/\"train/*.jpg\"))\n",
        "\t\tdataset = dataset.map(ReadTrainExample(height, width),\n",
        "\t\t\tnum_parallel_calls=AUTO)\n",
        "\t# otherwise, we are working with the test dataset\n",
        "\telse:\n",
        "\t\t# read the test examples\n",
        "\t\tdataset = tf.data.Dataset.list_files(str(path/\"val/*.jpg\"))\n",
        "\t\tdataset = dataset.map(ReadTestExample(height, width),\n",
        "\t\t\tnum_parallel_calls=AUTO)\n",
        "\n",
        "\t# shuffle, batch, repeat and prefetch the dataset\n",
        "\tdataset = (dataset\n",
        "\t\t.shuffle(batchSize * 2)\n",
        "\t\t.batch(batchSize)\n",
        "\t\t.repeat()\n",
        "\t\t.prefetch(AUTO)\n",
        "\t)\n",
        "\n",
        "\t# return the dataset\n",
        "\treturn dataset"
      ],
      "metadata": {
        "id": "ggk_yqEco7B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset into `tf.data` format"
      ],
      "metadata": {
        "id": "qcC4bbTbrqVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the training dataset\n",
        "print(\"[INFO] building the train dataset...\")\n",
        "trainDs = load_dataset(path=path, train=True,\n",
        "\tbatchSize=config.TRAIN_BATCH_SIZE, height=config.IMAGE_HEIGHT,\n",
        "\twidth=config.IMAGE_WIDTH)\n",
        "\n",
        "# build the test dataset\n",
        "print(\"[INFO] building the test dataset...\")\n",
        "testDs = load_dataset(path=path, train=False,\n",
        "\tbatchSize=config.INFER_BATCH_SIZE, height=config.IMAGE_HEIGHT,\n",
        "\twidth=config.IMAGE_WIDTH)"
      ],
      "metadata": {
        "id": "_Jx_pSYWokfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model utilities"
      ],
      "metadata": {
        "id": "ZCwDe1SUpYiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pix2Pix(object):\n",
        "\tdef __init__(self, imageHeight, imageWidth):\n",
        "\t\t# initialize the image height and width\n",
        "\t\tself.imageHeight = imageHeight\n",
        "\t\tself.imageWidth = imageWidth\n",
        "\n",
        "\tdef generator(self):\n",
        "\t\t# initialize the input layer\n",
        "\t\tinputs = Input([self.imageHeight, self.imageWidth, 3])\n",
        "  \n",
        "\t\t# down Layer 1 (d1) => final layer 1 (f1)\n",
        "\t\td1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(\n",
        "\t\t\tinputs)\n",
        "\t\td1 = Dropout(0.1)(d1)\n",
        "\t\tf1 = MaxPool2D((2, 2))(d1)\n",
        "\n",
        "\t\t# down Layer 2 (l2) => final layer 2 (f2)\n",
        "\t\td2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(f1)\n",
        "\t\tf2 = MaxPool2D((2, 2))(d2)\n",
        "\n",
        "\t\t#  down Layer 3 (l3) => final layer 3 (f3)\n",
        "\t\td3 = Conv2D(96, (3, 3), activation=\"relu\", padding=\"same\")(f2)\n",
        "\t\tf3 = MaxPool2D((2, 2))(d3)\n",
        "\n",
        "\t\t# down Layer 4 (l3) => final layer 4 (f4)\n",
        "\t\td4 = Conv2D(96, (3, 3), activation=\"relu\", padding=\"same\")(f3)\n",
        "\t\tf4 = MaxPool2D((2, 2))(d4)\n",
        "\n",
        "\t\t# u-bend of the u-bet\n",
        "\t\tb5 = Conv2D(96, (3, 3), activation=\"relu\", padding=\"same\")(f4)\n",
        "\t\tb5 = Dropout(0.3)(b5)\n",
        "\t\tb5 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(b5)\n",
        "\n",
        "\t\t# upsample Layer 6 (u6)\n",
        "\t\tu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\")(b5)\n",
        "\t\tu6 = concatenate([u6, d4])\n",
        "\t\tu6 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(\n",
        "\t\t\tu6)\n",
        "\n",
        "\t\t# upsample Layer 7 (u7)\n",
        "\t\tu7 = Conv2DTranspose(96, (2, 2), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\")(u6)\n",
        "\t\tu7 = concatenate([u7, d3])\n",
        "\t\tu7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(\n",
        "\t\t\tu7)\n",
        "\n",
        "\t\t# upsample Layer 8 (u8)\n",
        "\t\tu8 = Conv2DTranspose(64, (2, 2), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\")(u7)\n",
        "\t\tu8 = concatenate([u8, d2])\n",
        "\t\tu8 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u8)\n",
        "\n",
        "\t\t# upsample Layer 9 (u9)\n",
        "\t\tu9 = Conv2DTranspose(32, (2, 2), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\")(u8)\n",
        "\t\tu9 = concatenate([u9, d1])\n",
        "\t\tu9 = Dropout(0.1)(u9)\n",
        "\t\tu9 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u9)\n",
        "\n",
        "\t\t# final conv2D layer\n",
        "\t\toutputLayer = Conv2D(3, (1, 1), activation=\"tanh\")(u9)\n",
        "\t\n",
        "\t\t# create the generator model\n",
        "\t\tgenerator = Model(inputs, outputLayer)\n",
        "\n",
        "\t\t# return the generator\n",
        "\t\treturn generator\n",
        "\n",
        "\tdef discriminator(self):\n",
        "\t\t# initialize input layer according to PatchGAN\n",
        "\t\tinputMask = Input(shape=[self.imageHeight, self.imageWidth, 3], \n",
        "\t\t\tname=\"input_image\"\n",
        "\t\t)\n",
        "\t\ttargetImage = Input(\n",
        "\t\t\tshape=[self.imageHeight, self.imageWidth, 3], \n",
        "\t\t\tname=\"target_image\"\n",
        "\t\t)\n",
        "  \n",
        "\t\t# concatenate the inputs\n",
        "\t\tx = concatenate([inputMask, targetImage])  \n",
        "\n",
        "\t\t# add four conv2D convolution layers\n",
        "\t\tx = Conv2D(64, 4, strides=2, padding=\"same\")(x)  \n",
        "\t\tx = LeakyReLU()(x)\n",
        "\t\tx = Conv2D(128, 4, strides=2, padding=\"same\")(x)\n",
        "\t\tx = LeakyReLU()(x)  \n",
        "\t\tx = Conv2D(256, 4, strides=2, padding=\"same\")(x)\n",
        "\t\tx = LeakyReLU()(x)   \n",
        "\t\tx = Conv2D(512, 4, strides=1, padding=\"same\")(x)  \n",
        "\n",
        "\t\t# add a batch-normalization layer => LeakyReLU => zeropad\n",
        "\t\tx = BatchNormalization()(x)\n",
        "\t\tx = LeakyReLU()(x)\n",
        "\n",
        "\t\t# final conv layer\n",
        "\t\tlast = Conv2D(1, 3, strides=1)(x) \n",
        "  \n",
        "\t\t# create the discriminator model\n",
        "\t\tdiscriminator = Model(inputs=[inputMask, targetImage],\n",
        "\t\t\toutputs=last)\n",
        "\n",
        "\t\t# return the discriminator\n",
        "\t\treturn discriminator"
      ],
      "metadata": {
        "id": "BnYI2YiHpFYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Pix2Pix GAN model"
      ],
      "metadata": {
        "id": "MmK9ghP8rvLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the generator and discriminator network\n",
        "print(\"[INFO] initializing the generator and discriminator...\")\n",
        "pix2pixObject = Pix2Pix(imageHeight=config.IMAGE_HEIGHT,\n",
        "\timageWidth=config.IMAGE_WIDTH)\n",
        "generator = pix2pixObject.generator()\n",
        "discriminator = pix2pixObject.discriminator()"
      ],
      "metadata": {
        "id": "Z5DIY1AypAsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training utilities"
      ],
      "metadata": {
        "id": "KJ766JGSryA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pix2PixTraining(Model):\n",
        "\tdef __init__(self, generator, discriminator):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# initialize the generator, discriminator\n",
        "\t\tself.generator = generator\n",
        "\t\tself.discriminator = discriminator\n",
        "\n",
        "\tdef compile(self, gOptimizer, dOptimizer, bceLoss, maeLoss):\n",
        "\t\tsuper().compile()\n",
        "\t\t# initialize the optimizers for the generator \n",
        "\t\t# and discriminator\n",
        "\t\tself.gOptimizer = gOptimizer\n",
        "\t\tself.dOptimizer = dOptimizer\n",
        "\t\t\n",
        "\t\t# initialize the loss functions\n",
        "\t\tself.bceLoss = bceLoss\n",
        "\t\tself.maeLoss = maeLoss\n",
        "\t\n",
        "\tdef train_step(self, inputs):\n",
        "\t\t# grab the input mask and corresponding real images\n",
        "\t\t(inputMask, realImages) = inputs\n",
        "\n",
        "\t\t# initialize gradient tapes for both generator and discriminator\n",
        "\t\twith tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n",
        "\t\t\t# generate fake images\n",
        "\t\t\tfakeImages = self.generator(inputMask, training=True)\n",
        "\n",
        "\t\t\t# discriminator output for real images and fake images\n",
        "\t\t\tdiscRealOutput = self.discriminator(\n",
        "\t\t\t\t[inputMask, realImages], training=True)\n",
        "\t\t\tdiscFakeOutput = self.discriminator(\n",
        "\t\t\t\t[inputMask, fakeImages], training=True)\n",
        "\n",
        "\t\t\t# compute the adversarial loss for the generator\n",
        "\t\t\tmisleadingImageLabels = tf.ones_like(discFakeOutput) \n",
        "\t\t\tganLoss = self.bceLoss(misleadingImageLabels, discFakeOutput)\n",
        "\n",
        "\t\t\t# compute the mean absolute error between the fake and the\n",
        "\t\t\t# real images\n",
        "\t\t\tl1Loss = self.maeLoss(realImages, fakeImages)\n",
        "\n",
        "\t\t\t# compute the total generator loss\n",
        "\t\t\ttotalGenLoss = ganLoss + (10 * l1Loss)\n",
        "\n",
        "\t\t\t# discriminator loss for real and fake images\n",
        "\t\t\trealImageLabels = tf.ones_like(discRealOutput)\n",
        "\t\t\trealDiscLoss = self.bceLoss(realImageLabels, discRealOutput)\n",
        "\t\t\tfakeImageLabels = tf.zeros_like(discFakeOutput)\n",
        "\t\t\tgeneratedLoss = self.bceLoss(fakeImageLabels, discFakeOutput)\n",
        "\n",
        "\t\t\t# compute the total discriminator loss\n",
        "\t\t\ttotalDiscLoss = realDiscLoss + generatedLoss\n",
        "\n",
        "\t\t# calculate the generator and discriminator gradients\n",
        "\t\tgeneratorGradients = genTape.gradient(totalGenLoss, \n",
        "\t\t\tself.generator.trainable_variables\n",
        "\t\t)\n",
        "\t\tdiscriminatorGradients = discTape.gradient(totalDiscLoss, \n",
        "\t\t\tself.discriminator.trainable_variables\n",
        "\t\t)\n",
        "\n",
        "\t\t# apply the gradients to optimize the generator and discriminator\n",
        "\t\tself.gOptimizer.apply_gradients(zip(generatorGradients,\n",
        "\t\t\tself.generator.trainable_variables)\n",
        "\t\t)\n",
        "\t\tself.dOptimizer.apply_gradients(zip(discriminatorGradients,\n",
        "\t\t\tself.discriminator.trainable_variables)\n",
        "\t\t)\n",
        "\n",
        "\t\t# return the generator and discriminator losses\n",
        "\t\treturn {\"dLoss\": totalDiscLoss, \"gLoss\": totalGenLoss}"
      ],
      "metadata": {
        "id": "yV7Pf3_jpi7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the trainer"
      ],
      "metadata": {
        "id": "xLgHCZgzr03P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the pix2pix training model and compile it\n",
        "pix2pixModel = Pix2PixTraining(\n",
        "\tgenerator=generator,\n",
        "\tdiscriminator=discriminator)\n",
        "pix2pixModel.compile(\n",
        "\tdOptimizer=Adam(learning_rate=config.LEARNING_RATE),\n",
        "\tgOptimizer=Adam(learning_rate=config.LEARNING_RATE),\n",
        "\tbceLoss=BinaryCrossentropy(from_logits=True),\n",
        "\tmaeLoss=MeanAbsoluteError(),\n",
        ")"
      ],
      "metadata": {
        "id": "hs8FIGG-pct4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor Callback"
      ],
      "metadata": {
        "id": "bP96tng7r3L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether output model directory exists\n",
        "# if it doesn't, then create it\n",
        "if not os.path.exists(config.TEMP_BASE_OUTPUT_PATH):\n",
        "\tos.makedirs(config.TEMP_BASE_OUTPUT_PATH)\n",
        "\n",
        "# check whether output image directory exists, if it doesn't, then\n",
        "# create it\n",
        "if not os.path.exists(config.TEMP_BASE_IMAGES_PATH):\n",
        "\tos.makedirs(config.TEMP_BASE_IMAGES_PATH)"
      ],
      "metadata": {
        "id": "Wpyb6PlMqNez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_monitor(testDs, imagePath, batchSize, epochInterval):\n",
        "\t# grab the input mask and the real image from the testing dataset\n",
        "\t(tInputMask, tRealImage) = next(iter(testDs))\n",
        "\n",
        "\tclass TrainMonitor(Callback):\n",
        "\t\tdef __init__(self, epochInterval=None):\n",
        "\t\t\tself.epochInterval = epochInterval\n",
        "\n",
        "\t\tdef on_epoch_end(self, epoch, logs=None):\n",
        "\t\t\tif self.epochInterval and epoch % self.epochInterval == 0:\n",
        "\t\t\t\t# get the pix2pix prediction\n",
        "\t\t\t\ttPix2pixGenPred = self.model.generator.predict(tInputMask)\n",
        "\n",
        "\t\t\t\t(fig, axes) = subplots(nrows=batchSize, ncols=3,\n",
        "\t\t\t\t\tfigsize=(5, 20))\n",
        "\n",
        "\t\t\t\t# plot the predicted images \n",
        "\t\t\t\tfor (ax, inp, pred, tgt) in zip(axes, tInputMask,\n",
        "\t\t\t\t\ttPix2pixGenPred, tRealImage):\n",
        "\t\t\t\t\t# plot the input mask image\n",
        "\t\t\t\t\tax[0].imshow(array_to_img(inp))\n",
        "\t\t\t\t\tax[0].set_title(\"Input Image\")\n",
        "\n",
        "\t\t\t\t\t# plot the predicted Pix2Pix image\n",
        "\t\t\t\t\tax[1].imshow(array_to_img(pred))\n",
        "\t\t\t\t\tax[1].set_title(\"Pix2Pix Prediction\")\n",
        "\n",
        "\t\t\t\t\t# plot the ground truth\n",
        "\t\t\t\t\tax[2].imshow(array_to_img(tgt))\n",
        "\t\t\t\t\tax[2].set_title(\"Target Label\")\n",
        "\n",
        "\t\t\t\tplt.show()\n",
        "\t\n",
        "\t# instantiate a train monitor callback\n",
        "\ttrainMonitor = TrainMonitor(epochInterval=epochInterval)\n",
        "\n",
        "\t# return the train monitor\n",
        "\treturn trainMonitor"
      ],
      "metadata": {
        "id": "wHLnwmwrqL3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n",
        "\n",
        "In the colab notebook, we train the model for a smaller epochs (due to time constraints) to show how the model trains. In the blog post we have trained the GAN for **150** epochs which gives us good results. We have provided our trained model for inference. \n",
        "\n",
        "If you want to infer on the trained model, jump straight over to the inference section 🤩."
      ],
      "metadata": {
        "id": "qUFReu7nr8C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the pix2pix model\n",
        "print(\"[INFO] training the pix2pix model...\")\n",
        "callbacks = [get_train_monitor(testDs, epochInterval=10,\n",
        "\timagePath=config.TEMP_BASE_IMAGES_PATH,\n",
        "\tbatchSize=config.INFER_BATCH_SIZE)]\n",
        "\n",
        "pix2pixModel.fit(trainDs, epochs=config.EPOCHS, callbacks=callbacks,\n",
        "\tsteps_per_epoch=config.STEPS_PER_EPOCH)\n",
        "\n",
        "# set the path for the generator\n",
        "genPath = config.TEMP_GENERATOR_MODEL\n",
        "\n",
        "# save the pix2pix generator\n",
        "print(f\"[INFO] saving pix2pix generator to {genPath}...\")\n",
        "pix2pixModel.generator.save(genPath)"
      ],
      "metadata": {
        "id": "7T6BMPYJpfNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "vHqJnPGosRCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the first batch of testing images\n",
        "(inputMask, realImage) = next(iter(testDs))\n",
        "\n",
        "# set the path for the generator\n",
        "genPath = config.GENERATOR_MODEL\n",
        "\n",
        "# load the trained pix2pix generator\n",
        "print(\"[INFO] loading the trained pix2pix generator...\")\n",
        "pix2pixGen = load_model(genPath, compile=False)\n",
        "\t\n",
        "# predict using pix2pix generator\n",
        "print(\"[INFO] making predictions with the generator...\")\n",
        "pix2pixGenPred = pix2pixGen.predict(inputMask)\n",
        "\n",
        "# plot the respective predictions\n",
        "print(\"[INFO] saving the predictions...\")\n",
        "(fig, axes) = subplots(nrows=config.INFER_BATCH_SIZE, ncols=3,\n",
        "\tfigsize=(10, 30))\n",
        "\n",
        "# plot the predicted images \n",
        "for (ax, inp, pred, tgt) in zip(axes, inputMask, pix2pixGenPred,\n",
        "\trealImage):\n",
        "\t# plot the input mask image\n",
        "\tax[0].imshow(array_to_img(inp))\n",
        "\tax[0].set_title(\"Input Image\")\n",
        "\n",
        "\t# plot the predicted Pix2Pix image\n",
        "\tax[1].imshow(array_to_img(pred))\n",
        "\tax[1].set_title(\"Pix2Pix Prediction\")\n",
        "\n",
        "\t# plot the ground truth\n",
        "\tax[2].imshow(array_to_img(tgt))\n",
        "\tax[2].set_title(\"Target Label\")\n",
        "\n",
        "# check whether output image directory exists, if it doesn't, then\n",
        "# create it\n",
        "if not os.path.exists(config.BASE_IMAGES_PATH):\n",
        "\tos.makedirs(config.BASE_IMAGES_PATH)\n",
        "\n",
        "# serialize the results to disk\n",
        "print(\"[INFO] saving the pix2pix predictions to disk...\")\n",
        "fig.savefig(config.GRID_IMAGE_PATH)"
      ],
      "metadata": {
        "id": "lGXx67vSqPbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Image Translation with Pix2Pix*](https://pyimg.co/ma1qi) published on 2022-07-27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sef8alx4cGYc"
      },
      "source": [
        "# Code License Agreement\n",
        "```\n",
        "Copyright (c) 2022 PyImageSearch.com\n",
        "\n",
        "SIMPLE VERSION\n",
        "Feel free to use this code for your own projects, whether they are\n",
        "purely educational, for fun, or for profit. THE EXCEPTION BEING if\n",
        "you are developing a course, book, or other educational product.\n",
        "Under *NO CIRCUMSTANCE* may you use this code for your own paid\n",
        "educational or self-promotional ventures without written consent\n",
        "from OptiReto, LLC and PyImageSearch.com.\n",
        "\n",
        "LONGER, FORMAL VERSION\n",
        "Permission is hereby granted, free of charge, to any person obtaining\n",
        "a copy of this software and associated documentation files\n",
        "(the \"Software\"), to deal in the Software without restriction,\n",
        "including without limitation the rights to use, copy, modify, merge,\n",
        "publish, distribute, sublicense, and/or sell copies of the Software,\n",
        "and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be\n",
        "included in all copies or substantial portions of the Software.\n",
        "Notwithstanding the foregoing, you may not use, copy, modify, merge,\n",
        "publish, distribute, sublicense, create a derivative work, and/or\n",
        "sell copies of the Software in any work that is designed, intended,\n",
        "or marketed for pedagogical or instructional purposes related to\n",
        "programming, coding, application development, or information\n",
        "technology. Permission for such use, copying, modification, and\n",
        "merger, publication, distribution, sub-licensing, creation of\n",
        "derivative works, or sale is expressly withheld.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
        "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
        "OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
        "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n",
        "BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n",
        "ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```"
      ]
    }
  ]
}